# Ø¨ÙˆØª Ø®ÙÙŠÙ Ù„Ø§ ÙŠØ­ØªØ§Ø¬ ffmpeg Ø£Ùˆ pydub
# ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Vosk Ø£Ùˆ SpeechRecognition
# ÙŠØ¯Ø¹Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©ØŒ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ ÙˆÙŠÙ‚Ø³Ù… Ø§Ù„Ù†Øµ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø±Ø³Ø§Ø¦Ù„

from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
import os
import math
import time

TOKEN = os.environ.get("TOKEN", "8584666863:AAHZ3xApgMsvioTzkd7BoIed38z5VKCSYaE")
MAX_MESSAGE_LENGTH = 3500
CHUNK_LENGTH_MS = 60_000

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©
USE_VOSK = False
USE_SPEECHREC = False
try:
    from vosk import Model, KaldiRecognizer
    USE_VOSK = True
except:
    import speech_recognition as sr
    USE_SPEECHREC = True

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Vosk Ø¥Ø°Ø§ Ù…ØªÙˆÙØ±
if USE_VOSK:
    if not os.path.exists("vosk-model"):
        print("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ VoskØŒ ÙŠØ¬Ø¨ ØªØ­Ù…ÙŠÙ„Ù‡ ÙŠØ¯ÙˆÙŠÙ‹Ø§")
    else:
        vosk_model = Model("vosk-model")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ™ï¸ Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø£Ø±Ø³Ù„ Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ© Ù„Ø£Ø­ÙˆÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù†Øµ")

async def send_long_text(message, text):
    for i in range(0, len(text), MAX_MESSAGE_LENGTH):
        await message.reply_text(text[i:i + MAX_MESSAGE_LENGTH])

async def speech_to_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    if not (message.voice or message.audio):
        await message.reply_text("âš ï¸ Ø£Ø±Ø³Ù„ Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ© Ø£Ùˆ Ù…Ù„Ù ØµÙˆØªÙŠ ÙÙ‚Ø·")
        return

    file = await (message.voice.get_file() if message.voice else message.audio.get_file())
    input_path = "input_audio"
    wav_path = "full_audio.wav"
    await file.download_to_drive(input_path)

    full_text = ""

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Wave (Ø¨Ø¯ÙˆÙ† pydub)
    import wave
    with wave.open(input_path, 'rb') as wf:
        frames = wf.getnframes()
        rate = wf.getframerate()
        duration_ms = (frames / rate) * 1000
        chunks = math.ceil(duration_ms / CHUNK_LENGTH_MS)

        progress_message = await message.reply_text(
            f"â³ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...\nğŸ”„ Ø§Ù„ØªÙ‚Ø¯Ù…: 0% (0 / {chunks})\nâ±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ: --"
        )

        for i in range(chunks):
            start_frame = int(i * CHUNK_LENGTH_MS * rate / 1000)
            end_frame = int(min((i + 1) * CHUNK_LENGTH_MS * rate / 1000, frames))
            wf.setpos(start_frame)
            data = wf.readframes(end_frame - start_frame)

            text = ""
            if USE_VOSK:
                import json
                rec = KaldiRecognizer(vosk_model, rate)
                if rec.AcceptWaveform(data):
                    res = json.loads(rec.Result())
                    text = res.get('text','')
            elif USE_SPEECHREC:
                r = sr.Recognizer()
                from io import BytesIO
                audio_file = sr.AudioFile(BytesIO(data))
                with audio_file as source:
                    audio_data = r.record(source)
                    try:
                        text = r.recognize_google(audio_data, language="ar-AR")
                    except:
                        try:
                            text = r.recognize_google(audio_data, language="en-US")
                        except:
                            text = ""

            if text:
                full_text += text + "\n"

            # ØªØ­Ø¯ÙŠØ« Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ‚Ø¯Ù…
            elapsed = time.time() - update.message.date.timestamp()
            completed = i + 1
            avg_time_per_chunk = elapsed / completed if completed else 0
            remaining_chunks = chunks - completed
            remaining_seconds = int(avg_time_per_chunk * remaining_chunks)
            minutes = remaining_seconds // 60
            seconds = remaining_seconds % 60
            percent = int((completed / chunks) * 100)

            await progress_message.edit_text(
                f"â³ Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª...\n"
                f"ğŸ”„ Ø§Ù„ØªÙ‚Ø¯Ù…: {percent}% ({completed} / {chunks})\n"
                f"â±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ: {minutes} Ø¯Ù‚ÙŠÙ‚Ø© {seconds} Ø«Ø§Ù†ÙŠØ©"
            )

    if os.path.exists(input_path): os.remove(input_path)

    if not full_text.strip():
        await progress_message.edit_text("âš ï¸ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ ÙˆØ§Ø¶Ø­ Ù…Ù† Ø§Ù„ØµÙˆØª")
        return

    await progress_message.edit_text("âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø³Ø¨Ø© 100%")
    header = "ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ:\n\n"
    await send_long_text(message, header + full_text.strip())

if __name__ == '__main__':
    app = ApplicationBuilder().token(TOKEN).build()
    app.add_handler(CommandHandler('start', start))
    app.add_handler(MessageHandler(filters.VOICE | filters.AUDIO, speech_to_text))

    print("ğŸ‰ Lightweight Speech to Text Bot is running!")
    app.run_polling()
